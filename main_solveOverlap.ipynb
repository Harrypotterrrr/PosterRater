{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Poster Generation\n",
    "## 当前任务\n",
    "### 打分器（实际上可看作二分类问题）\n",
    "#### 1. 输入\n",
    "- 正样本：已有的海报图像，label为1\n",
    "- 负样本：在现有海报图像的基础上随机搭配，label为0\n",
    "\n",
    "#### 2. 网络结构\n",
    "- 可以用现有的卷积基模型，可能需要fine-tune\n",
    "- 也可以自己构造一个简单的模型（尝试）\n",
    "- 对于卷积基提取的特征，后面接上Flatten和Dense层，最后做一个二分类\n",
    "\n",
    "#### 3. 输出\n",
    "- 输出的概率值既可以看作是打分器的分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "    \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_width = 200\n",
    "standard_height = 280"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据集并进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from imgAugmentation.ipynb\n",
      "\n",
      "        use Gaussian nosiy to process image\n",
      "        :param image:\n",
      "        :return:\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import import_ipynb\n",
    "from imgAugmentation import ImageProcess\n",
    "\n",
    "\n",
    "def getAllFiles(rootDir):\n",
    "    files = []\n",
    "    fileList = os.listdir(rootDir) #列出文件夹下所有的目录与文件\n",
    "    \n",
    "    for i in fileList:\n",
    "        \n",
    "        path = os.path.join(rootDir, i)\n",
    "        if os.path.isdir(path):\n",
    "            files.extend(getAllFiles(path))\n",
    "        elif os.path.isfile(path):\n",
    "            files.append(path)\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_positive = glob.glob('./data/poster_positive_data/*.png')\n",
    "poster_positive += glob.glob('./data/poster_positive_ori/*.png')\n",
    "\n",
    "poster_negative = glob.glob('./data/poster_negative_data/*.png')\n",
    "poster_negative += glob.glob('./data/poster_negative_ori/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poster positive num: 18601\n",
      "poster negative num: 18222\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(poster_positive)\n",
    "np.random.shuffle(poster_negative)\n",
    "poster_positive_num = len(poster_positive)\n",
    "poster_negative_num = len(poster_negative)\n",
    "\n",
    "print(\"poster positive num: \" + str(poster_positive_num))\n",
    "print(\"poster negative num: \" + str(poster_negative_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用RGB图像训练-多进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to process\n",
      "(16000, 280, 200, 3) (16000, 1)\n",
      "train set initialization finished!\n",
      "(400, 280, 200, 3) (400, 1)\n",
      "validation set initialization finished!\n",
      "(400, 280, 200, 3) (400, 1)\n",
      "test set initialization finished!\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import sharedctypes\n",
    "import ctypes\n",
    "\n",
    "debug = False\n",
    "\n",
    "num_train_positive = 8000\n",
    "num_train_negative = 8000\n",
    "\n",
    "num_validation_positive = 200\n",
    "num_validation_negative = 200\n",
    "\n",
    "num_test_positive = 200\n",
    "num_test_negative = 200\n",
    "\n",
    "# tuple(number, height, width, dimension)\n",
    "\n",
    "X_train = np.ctypeslib.as_ctypes(np.empty((num_train_positive + num_train_negative, standard_height, standard_width, 3)))\n",
    "Y_train = np.ctypeslib.as_ctypes(np.empty((num_train_positive + num_train_negative, 1)))\n",
    "\n",
    "X_validation = np.ctypeslib.as_ctypes(np.empty((num_validation_positive + num_validation_negative, standard_height, standard_width, 3)))\n",
    "Y_validation = np.ctypeslib.as_ctypes(np.empty((num_validation_positive + num_validation_negative, 1)))\n",
    "\n",
    "X_test = np.ctypeslib.as_ctypes(np.empty((num_test_positive + num_test_negative, standard_height, standard_width, 3)))\n",
    "Y_test = np.ctypeslib.as_ctypes(np.empty((num_test_positive + num_test_negative, 1)))\n",
    "\n",
    "# create Shared_memory of each set\n",
    "X_train_sh = sharedctypes.RawArray(X_train._type_, X_train)\n",
    "Y_train_sh = sharedctypes.RawArray(Y_train._type_, Y_train)\n",
    "\n",
    "X_validation_sh = sharedctypes.RawArray(X_validation._type_, X_validation)\n",
    "Y_validation_sh = sharedctypes.RawArray(Y_validation._type_, Y_validation)\n",
    "\n",
    "X_test_sh = sharedctypes.RawArray(X_test._type_, X_test)\n",
    "Y_test_sh = sharedctypes.RawArray(Y_test._type_, Y_test)\n",
    "\n",
    "\n",
    "print('begin to process')\n",
    "\n",
    "def trainSetPositive(i):\n",
    "    try:\n",
    "        im = Image.open(poster_positive[i]).convert('RGB')\n",
    "        X_train_sh[i] = np.ctypeslib.as_ctypes(np.array(im) / 255.)\n",
    "        Y_train_sh[i] = np.ctypeslib.as_ctypes(np.array([1.]))\n",
    "        if debug:\n",
    "            print('finish train positive', i)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def trainSetNegative(i):\n",
    "    try:\n",
    "        im = Image.open(poster_negative[i]).convert('RGB')\n",
    "        X_train_sh[num_train_positive + i] = np.ctypeslib.as_ctypes(np.array(im) / 255.)\n",
    "        Y_train_sh[num_train_positive + i] = np.ctypeslib.as_ctypes(np.array([0.]))\n",
    "        if debug:\n",
    "            print('finish train negative', i)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "def validationSetPositive(i):\n",
    "    im = Image.open(poster_positive[num_train_positive + i]).convert('RGB')\n",
    "    X_validation_sh[i] = np.ctypeslib.as_ctypes(np.array(im) / 255.)\n",
    "    Y_validation_sh[i] = np.ctypeslib.as_ctypes(np.array([1.]))\n",
    "    if debug:\n",
    "        print('finish validation positive', i)\n",
    "    \n",
    "def validationSetNegative(i):\n",
    "    im = Image.open(poster_negative[num_train_negative + i]).convert('RGB')\n",
    "    X_validation_sh[num_validation_positive + i] = np.ctypeslib.as_ctypes(np.array(im) / 255.)\n",
    "    Y_validation_sh[num_validation_positive + i] = np.ctypeslib.as_ctypes(np.array([0.]))\n",
    "    if debug:\n",
    "        print('finish validation negative', i)\n",
    "    \n",
    "def testSetPositive(i):\n",
    "    im = Image.open(poster_positive[num_train_positive + num_validation_positive + i]).convert('RGB')\n",
    "    X_test_sh[i] = np.ctypeslib.as_ctypes(np.array(im) / 255.)\n",
    "    Y_test_sh[i] = np.ctypeslib.as_ctypes(np.array([1.]))\n",
    "    if debug:\n",
    "        print('finish test positive', i)\n",
    "    \n",
    "def testSetNegative(i):\n",
    "    im = Image.open(poster_negative[num_train_negative + num_validation_negative + i]).convert('RGB')\n",
    "    X_test_sh[num_test_positive + i] = np.ctypeslib.as_ctypes(np.array(im) / 255.)\n",
    "    Y_test_sh[num_test_positive + i] = np.ctypeslib.as_ctypes(np.array([0.]))\n",
    "    if debug:\n",
    "        print('finish test negative', i)\n",
    "    \n",
    "# initialize the process pool\n",
    "## ATTENTION: pool must be initialized after function\n",
    "pool = Pool()\n",
    "\n",
    "\n",
    "# make train set\n",
    "\n",
    "for i in range(num_train_positive):\n",
    "    pool.apply_async(trainSetPositive, args=(i,))\n",
    "for i in range(num_train_negative):\n",
    "    pool.apply_async(trainSetNegative, args=(i,))\n",
    "\n",
    "# convert Ctype to numpy\n",
    "X_train = np.ctypeslib.as_array(X_train_sh)\n",
    "Y_train = np.ctypeslib.as_array(Y_train_sh)\n",
    "    \n",
    "# # shuffle the whole train set\n",
    "# zipped = list(zip(X_train, Y_train))\n",
    "# np.random.shuffle(zipped)\n",
    "# X_train[:], Y_train[:] = zip(*zipped)\n",
    "\n",
    "# another shuffle method\n",
    "index = [i for i in range(len(X_train))]\n",
    "random.shuffle(index)\n",
    "X_train = X_train[index]\n",
    "Y_train = Y_train[index]\n",
    "\n",
    "\n",
    "print(np.array(X_train).shape, np.array(Y_train).shape)\n",
    "assert len(X_train) == len(Y_train)\n",
    "\n",
    "print(\"train set initialization finished!\")\n",
    "\n",
    "# make validation set\n",
    "\n",
    "for i in range(num_validation_positive):\n",
    "    pool.apply_async(validationSetPositive, args=(i,))\n",
    "    \n",
    "for i in range(num_validation_negative):\n",
    "    pool.apply_async(validationSetNegative, args=(i,))\n",
    "\n",
    "# convert Ctype to numpy\n",
    "X_validation = np.ctypeslib.as_array(X_validation_sh)\n",
    "Y_validation = np.ctypeslib.as_array(Y_validation_sh)\n",
    "\n",
    "print(np.array(X_validation).shape, np.array(Y_validation).shape)\n",
    "assert len(X_validation) == len(Y_validation)\n",
    "\n",
    "print(\"validation set initialization finished!\")\n",
    "\n",
    "# make test set\n",
    "for i in range(num_test_positive):\n",
    "    pool.apply_async(testSetPositive, args=(i,))\n",
    "\n",
    "for i in range(num_test_negative):\n",
    "    pool.apply_async(testSetNegative, args=(i,))\n",
    "\n",
    "# convert Ctype to numpy\n",
    "X_test = np.ctypeslib.as_array(X_test_sh)\n",
    "Y_test = np.ctypeslib.as_array(Y_test_sh)\n",
    "\n",
    "print(np.array(X_test).shape, np.array(Y_test).shape)\n",
    "assert len(X_test) == len(Y_test)\n",
    "\n",
    "print(\"test set initialization finished!\")\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test for data production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)\n",
    "print(Y_train[0:50])\n",
    "# print(X_test.shape)\n",
    "# print(Y_test.shape)\n",
    "# print(Y_test[10:50])\n",
    "# print(X_validation.shape)\n",
    "# print(Y_validation.shape)\n",
    "# print(Y_validation[10:50])\n",
    "\n",
    "ctr = 0\n",
    "for i in Y_train:\n",
    "    if i == 1.0:\n",
    "        ctr += 1\n",
    "print(len(Y_train))\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将VGG16卷积基实例化\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(standard_height, standard_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 280, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 280, 200, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 280, 200, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 140, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 140, 100, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 140, 100, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 70, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 70, 50, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 70, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 70, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 35, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 35, 25, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 35, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 35, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 17, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 17, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 17, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 17, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 6, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在卷积基上添加一个密集链接分类器\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "# model = models.Sequential()\n",
    "# model.add(conv_base)\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(256, activation='relu',\n",
    "#                        kernel_initializer='glorot_normal', bias_initializer='zeros',\n",
    "#                        kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.01)))\n",
    "# model.add(layers.Dense(1,activation='sigmoid', kernel_initializer='glorot_normal', bias_initializer='zeros'))\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 8, 6, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 24576)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               6291712   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 21,006,657\n",
      "Trainable params: 21,006,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# freeze the pre-train model VGG\n",
    "conv_base.trainable = False\n",
    "print(len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights\n",
    "model_path = './model_save/'\n",
    "model_name = 'vgg16_final.h5'\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdirs(model_path)\n",
    "    print(\"create new dirctory:\", model_path)\n",
    "if os.path.isfile(model_path + model_name):\n",
    "    model.load_weights(model_path + model_name)\n",
    "    print(\"load weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 400 samples\n",
      "Epoch 1/5\n",
      "16000/16000 [==============================] - 281s 18ms/step - loss: 0.7063 - acc: 0.6961 - val_loss: 0.4708 - val_acc: 0.7600\n",
      "Epoch 2/5\n",
      "16000/16000 [==============================] - 268s 17ms/step - loss: 0.4767 - acc: 0.7671 - val_loss: 0.3262 - val_acc: 0.8375\n",
      "Epoch 3/5\n",
      "16000/16000 [==============================] - 268s 17ms/step - loss: 0.4215 - acc: 0.7990 - val_loss: 0.3116 - val_acc: 0.8600\n",
      "Epoch 4/5\n",
      "16000/16000 [==============================] - 268s 17ms/step - loss: 0.3771 - acc: 0.8214 - val_loss: 0.3794 - val_acc: 0.8300\n",
      "Epoch 5/5\n",
      "16000/16000 [==============================] - 268s 17ms/step - loss: 0.3569 - acc: 0.8281 - val_loss: 0.2959 - val_acc: 0.8750\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=70,\n",
    "                    validation_data=(X_validation, Y_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 10s 24ms/step\n",
      "[0.44907580375671385, 0.825]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, Y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights\n",
    "model.save_weights(model_path + model_name)\n",
    "\n",
    "# save the whole architecture\n",
    "arch_name = \"model_arch.h5\"\n",
    "model.save(model_path + arch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)\n",
    "print(predict)\n",
    "\n",
    "for i in range(20, 40):\n",
    "    plt.imshow(X_test[i])\n",
    "    plt.show()\n",
    "    print(\"predict:\",predict[i][0], \"label\", Y_test[i][0])\n",
    "\n",
    "for i in range(220, 240):\n",
    "    plt.imshow(X_test[i])\n",
    "    plt.show()\n",
    "    print(\"predict:\",predict[i][0], \"label\", Y_test[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def trainVisualization(hist):\n",
    "    loss = hist.history['loss']\n",
    "    val_loss = hist.history['val_loss']\n",
    "    acc = hist.history['acc']\n",
    "    val_acc = hist.history['val_acc']\n",
    "\n",
    "    # make a figure\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "\n",
    "    # subplot loss\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.plot(loss,label='train_loss')\n",
    "    ax1.plot(val_loss,label='val_loss')\n",
    "    ax1.scatter(history.epoch, history.history['loss'], marker='*')\n",
    "    ax1.scatter(history.epoch, history.history['val_loss'], marker='*')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Loss on Training and Validation Data')\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    # subplot acc\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.plot(acc,label='train_acc')\n",
    "    ax2.plot(val_acc,label='val_acc')\n",
    "    ax2.scatter(history.epoch, history.history['acc'], marker='*')\n",
    "    ax2.scatter(history.epoch, history.history['val_acc'])\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Accuracy  on Training and Validation Data')\n",
    "    ax1.legend(loc='lower right')\n",
    "\n",
    "trainVisualization(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
