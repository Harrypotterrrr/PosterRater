{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Poster Generation\n",
    "## 当前任务\n",
    "### 打分器（实际上可看作二分类问题）\n",
    "#### 1. 输入\n",
    "- 正样本：已有的海报图像，label为1\n",
    "- 负样本：在现有海报图像的基础上随机搭配，label为0\n",
    "\n",
    "#### 2. 网络结构\n",
    "- 可以用现有的卷积基模型，可能需要fine-tune\n",
    "- 也可以自己构造一个简单的模型（尝试）\n",
    "- 对于卷积基提取的特征，后面接上Flatten和Dense层，最后做一个二分类\n",
    "\n",
    "#### 3. 输出\n",
    "- 输出的概率值既可以看作是打分器的分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangh/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_width = 200\n",
    "standard_height = 280"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据集并进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poster positive num: 369\n",
      "poster negative num: 1690\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "poster_positive = glob.glob('poster_positive/*.png')\n",
    "poster_negative = glob.glob('poster_negative/*.png')\n",
    "np.random.shuffle(poster_positive)\n",
    "np.random.shuffle(poster_negative)\n",
    "poster_positive_num = len(poster_positive)\n",
    "poster_negative_num = len(poster_negative)\n",
    "\n",
    "print(\"poster positive num: \" + str(poster_positive_num))\n",
    "print(\"poster negative num: \" + str(poster_negative_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "num_train_positive = 297\n",
    "# num_train_negative = 1352\n",
    "num_train_negative = 297\n",
    "num_validation_positive = 36\n",
    "# num_validation_negative = 169\n",
    "num_validation_negative = 36\n",
    "num_test_positive = 36\n",
    "# num_test_negative = 169\n",
    "num_test_negative = 36\n",
    "\n",
    "X_train = np.empty((num_train_positive + num_train_negative, standard_height, standard_width, 3))\n",
    "Y_train = np.empty((num_train_positive + num_train_negative, 1))\n",
    "\n",
    "X_validation = np.empty((num_validation_positive + num_validation_negative, standard_height, standard_width, 3))\n",
    "Y_validation = np.empty((num_validation_positive + num_validation_negative, 1))\n",
    "\n",
    "X_test = np.empty((num_test_positive + num_test_negative, standard_height, standard_width, 3))\n",
    "Y_test = np.empty((num_test_positive + num_test_negative, 1))\n",
    "\n",
    "for i in range(num_train_positive):\n",
    "    im = Image.open(poster_positive[i])\n",
    "    X_train[i] = np.asarray(im.convert('RGB'), dtype='float64') / 255.0  \n",
    "    Y_train[i] = 1\n",
    "    \n",
    "for i in range(num_train_negative):\n",
    "    im = Image.open(poster_negative[i])\n",
    "    X_train[num_train_positive + i] = np.asarray(im.convert('RGB'), dtype='float64') /255.0\n",
    "    Y_train[num_train_positive + i] = 0\n",
    "    \n",
    "index = [i for i in range(len(X_train))]\n",
    "random.shuffle(index)\n",
    "X_train = X_train[index]\n",
    "Y_train = Y_train[index]\n",
    "\n",
    "for i in range(num_validation_positive):\n",
    "    im = Image.open(poster_positive[num_train_positive + i])\n",
    "    X_validation[i] = np.asarray(im.convert('RGB'), dtype='float64') / 255.0  \n",
    "    Y_validation[i] = 1\n",
    "    \n",
    "for i in range(num_validation_negative):\n",
    "    im = Image.open(poster_negative[num_train_negative + i])\n",
    "    X_validation[num_validation_positive + i] = np.asarray(im.convert('RGB'), dtype='float64') /255.0\n",
    "    Y_validation[num_validation_positive + i] = 0\n",
    "    \n",
    "for i in range(num_test_positive):\n",
    "    im = Image.open(poster_positive[num_train_positive + num_validation_positive + i])\n",
    "    X_test[i] = np.asarray(im.convert('RGB'), dtype='float64') / 255.0  \n",
    "    Y_test[i] = 1\n",
    "    \n",
    "for i in range(num_test_negative):\n",
    "    im = Image.open(poster_negative[num_train_negative + num_validation_negative + i])\n",
    "    X_test[num_test_positive + i] = np.asarray(im.convert('RGB'), dtype='float64') /255.0\n",
    "    Y_test[num_test_positive + i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594, 280, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尝试使用VGG16卷积基预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将VGG16卷积基实例化\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(standard_height, standard_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 280, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 280, 200, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 280, 200, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 140, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 140, 100, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 140, 100, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 70, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 70, 50, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 70, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 70, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 35, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 35, 25, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 35, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 35, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 17, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 17, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 17, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 17, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 6, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在卷积基上添加一个密集链接分类器\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 8, 6, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 24576)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               6291712   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 21,006,657\n",
      "Trainable params: 21,006,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# 冻结卷积基\n",
    "conv_base.trainable = False\n",
    "print(len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译模型\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 594 samples, validate on 72 samples\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 13s 21ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 10s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 10s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 11s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 11s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 11s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 11s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 10s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 11s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 11s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 11s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 11s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 11s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 11s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 11s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 11s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 11s 19ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 11s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 11s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 11s 18ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_validation, Y_validation))\n",
    "\n",
    "model.save('scorer_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 4s 19ms/step\n",
      "[2.8304948703715804, 0.824390243902439]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, Y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2202587e-28],\n",
       "       [2.3821357e-35],\n",
       "       [6.0592483e-31],\n",
       "       [1.9981365e-30],\n",
       "       [5.4140457e-35],\n",
       "       [7.8003965e-26],\n",
       "       [1.4171536e-33],\n",
       "       [2.3576107e-34],\n",
       "       [2.9098714e-35],\n",
       "       [3.4425426e-29],\n",
       "       [1.9481839e-36],\n",
       "       [3.2786312e-33],\n",
       "       [1.5490261e-29],\n",
       "       [2.9990248e-27],\n",
       "       [2.3948029e-33],\n",
       "       [1.1887792e-32],\n",
       "       [3.3592285e-31],\n",
       "       [1.0056498e-31],\n",
       "       [6.1116849e-32],\n",
       "       [7.1948760e-31],\n",
       "       [3.4700209e-28],\n",
       "       [6.8970256e-32],\n",
       "       [1.5003061e-32],\n",
       "       [1.4438291e-29],\n",
       "       [3.7191051e-32],\n",
       "       [5.8929119e-30],\n",
       "       [2.2870056e-31],\n",
       "       [2.5476544e-30],\n",
       "       [6.7750094e-33],\n",
       "       [1.6833922e-34],\n",
       "       [1.7524684e-27],\n",
       "       [1.5371575e-31],\n",
       "       [8.2595729e-32],\n",
       "       [2.1702191e-26],\n",
       "       [3.4147817e-33],\n",
       "       [7.8177131e-31],\n",
       "       [2.2628704e-32],\n",
       "       [1.9103505e-35],\n",
       "       [5.1653352e-33],\n",
       "       [1.4244361e-28],\n",
       "       [1.3822853e-30],\n",
       "       [2.8547521e-29],\n",
       "       [5.9027155e-32],\n",
       "       [2.1923196e-33],\n",
       "       [3.7342512e-29],\n",
       "       [2.8517451e-31],\n",
       "       [1.8978756e-31],\n",
       "       [2.7256748e-30],\n",
       "       [7.5124485e-34],\n",
       "       [5.1518096e-28],\n",
       "       [4.8827872e-30],\n",
       "       [4.4480485e-31],\n",
       "       [1.6221855e-26],\n",
       "       [4.9520374e-32],\n",
       "       [1.1561944e-30],\n",
       "       [3.6848984e-34],\n",
       "       [2.1378893e-30],\n",
       "       [1.3262093e-32],\n",
       "       [5.1522911e-32],\n",
       "       [3.7940791e-32],\n",
       "       [2.5118692e-32],\n",
       "       [9.7628894e-28],\n",
       "       [8.4419263e-35],\n",
       "       [1.8050737e-33],\n",
       "       [5.5669975e-34],\n",
       "       [3.5721058e-30],\n",
       "       [4.9419865e-29],\n",
       "       [1.1586077e-33],\n",
       "       [1.0652444e-33],\n",
       "       [1.8955106e-30],\n",
       "       [8.0752606e-32],\n",
       "       [4.7324420e-34]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16预训练模型效果不好，接下来重新训练一个以Xception为卷积基的网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import Xception\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "conv_base_xception = Xception(include_top=False,\n",
    "                              input_shape=(standard_height, standard_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 280, 200, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 139, 99, 32)  864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 139, 99, 32)  128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 139, 99, 32)  0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 137, 97, 64)  18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 137, 97, 64)  256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 137, 97, 64)  0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 137, 97, 128) 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 137, 97, 128) 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 137, 97, 128) 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 137, 97, 128) 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 137, 97, 128) 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 69, 49, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 69, 49, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 69, 49, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 69, 49, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 69, 49, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 69, 49, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 69, 49, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 69, 49, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 69, 49, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 69, 49, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 35, 25, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 35, 25, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 35, 25, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 35, 25, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 35, 25, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 35, 25, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 35, 25, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 35, 25, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 35, 25, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 35, 25, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 18, 13, 728)  186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 18, 13, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 18, 13, 728)  2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 18, 13, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 18, 13, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 18, 13, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 18, 13, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 18, 13, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 18, 13, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 18, 13, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 18, 13, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 18, 13, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 18, 13, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 18, 13, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 18, 13, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 18, 13, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 18, 13, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 18, 13, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 18, 13, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 18, 13, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 18, 13, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 18, 13, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 18, 13, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 18, 13, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 18, 13, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 18, 13, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 18, 13, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 18, 13, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 18, 13, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 18, 13, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 18, 13, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 18, 13, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 18, 13, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 18, 13, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 18, 13, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 18, 13, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 18, 13, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 18, 13, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 18, 13, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 18, 13, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 18, 13, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 18, 13, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 18, 13, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 18, 13, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 18, 13, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 18, 13, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 18, 13, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 18, 13, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 18, 13, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 18, 13, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 18, 13, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 18, 13, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 18, 13, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 18, 13, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 18, 13, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 18, 13, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 18, 13, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 18, 13, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 18, 13, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 18, 13, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 18, 13, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 18, 13, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 18, 13, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 18, 13, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 18, 13, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 18, 13, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 18, 13, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 18, 13, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 18, 13, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 18, 13, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 18, 13, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 18, 13, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 18, 13, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 18, 13, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 18, 13, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 18, 13, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 18, 13, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 18, 13, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 18, 13, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 18, 13, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 18, 13, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 18, 13, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 18, 13, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 18, 13, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 18, 13, 728)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 18, 13, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 18, 13, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 18, 13, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 18, 13, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 18, 13, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 9, 7, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 9, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 9, 7, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 9, 7, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 9, 7, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 9, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 9, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 9, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 9, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 9, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base_xception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在xception卷积基上添加一个密集链接分类器\n",
    "\n",
    "model_xception = models.Sequential()\n",
    "model_xception.add(conv_base_xception)\n",
    "model_xception.add(layers.Flatten())\n",
    "model_xception.add(layers.Dense(256, activation='relu'))\n",
    "model_xception.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 9, 7, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 129024)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33030400  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 53,892,137\n",
      "Trainable params: 53,837,609\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_xception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n"
     ]
    }
   ],
   "source": [
    "print(len(model_xception.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译模型\n",
    "model_xception.compile(optimizer='rmsprop',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 594 samples, validate on 72 samples\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 29s 50ms/step - loss: 7.7748 - acc: 0.5017 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 29s 50ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 29s 49ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "from keras.backend import get_session\n",
    "\n",
    "get_session().run(tf.global_variables_initializer())\n",
    "\n",
    "history_xception = model_xception.fit(X_train,\n",
    "                                      Y_train,\n",
    "                                      epochs=20,\n",
    "                                      batch_size=16,\n",
    "                                      validation_data=(X_validation, Y_validation))\n",
    "\n",
    "model_xception.save('scorer_xception.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尝试加入style matrix(gram matrix)，这里还是使用VGG16，因为只包含卷积和池化基本操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将VGG16卷积基实例化，这次不含参数\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base_vgg16 = VGG16(include_top=False,\n",
    "                        input_shape=(standard_height, standard_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 280, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 280, 200, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 280, 200, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 140, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 140, 100, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 140, 100, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 70, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 70, 50, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 70, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 70, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 35, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 35, 25, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 35, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 35, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 17, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 17, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 17, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 17, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 6, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# style matrix(gram matrix)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# def gram_matrix(A):\n",
    "#     \"\"\"\n",
    "#     Argument:\n",
    "#     A -- matrix of shape (n_C, n_H*n_W)\n",
    "    \n",
    "#     Returns:\n",
    "#     GA -- Gram matrix of A, of shape (n_C, n_C)\n",
    "#     \"\"\"\n",
    "    \n",
    "#     GA = K.dot(A, K.transpose(A))\n",
    "    \n",
    "#     return GA\n",
    "\n",
    "def compute_layer_style(a_S):\n",
    "#     \"\"\"\n",
    "#     Arguments:\n",
    "#     a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S \n",
    "\n",
    "#     Returns: \n",
    "#     GS -- Gram matrix of S, of shape (n_C, n_C)        \n",
    "#     \"\"\"\n",
    "    \n",
    "    GS = K.batch_dot(a_S, a_S, axes=[1, 1])\n",
    "    \n",
    "    return GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建网络\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "def model_vgg16_style(input_shape):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = conv_base_vgg16(X_input)\n",
    "    \n",
    "    m, n_H, n_W, n_C = X.get_shape().as_list()\n",
    "    \n",
    "    X = layers.core.Reshape([n_H*n_W, n_C])(X)\n",
    "    \n",
    "    X = layers.core.Lambda(compute_layer_style)(X)\n",
    "    \n",
    "    X = layers.Flatten()(X)\n",
    "    \n",
    "    X = layers.Dense(256, activation='relu')(X)\n",
    "    \n",
    "    X = layers.Dense(256, activation='relu')(X)\n",
    "    \n",
    "    X = layers.Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    model_vgg16_style = Model(X_input, X)\n",
    "    \n",
    "    return model_vgg16_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16_style = model_vgg16_style((standard_height, standard_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        (None, 280, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                (None, 8, 6, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 48, 512)           0         \n",
      "_________________________________________________________________\n",
      "lambda_18 (Lambda)           (None, 512, 512)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 262144)            0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               67109120  \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 81,889,857\n",
      "Trainable params: 81,889,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg16_style.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译模型\n",
    "model_vgg16_style.compile(optimizer='rmsprop',\n",
    "                          loss='binary_crossentropy',\n",
    "                          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 594 samples, validate on 72 samples\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 27s 46ms/step - loss: 7.8557 - acc: 0.4899 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 27s 45ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 27s 45ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 27s 45ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 27s 45ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "from keras.backend import get_session\n",
    "\n",
    "get_session().run(tf.global_variables_initializer())\n",
    "\n",
    "history_vgg16_style = model_vgg16_style.fit(X_train,\n",
    "                                            Y_train,\n",
    "                                            epochs=5,\n",
    "                                            batch_size=16,\n",
    "                                            validation_data=(X_validation, Y_validation))\n",
    "\n",
    "model_vgg16_style.save('scorer_vgg16_style.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可能海报提取成高维特征后，就会不收敛，下面尝试搭建一个只带一次卷积池化的简单网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "def Simple_Model(input_shape):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "        \n",
    "    X = layers.ZeroPadding2D((3, 3))(X_input)\n",
    "        \n",
    "    X = layers.Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = layers.BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "        \n",
    "    X = layers.MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "        \n",
    "    X = layers.Flatten()(X)\n",
    "    X = layers.Dense(1, activation='sigmoid', name='fc')(X)\n",
    "        \n",
    "    simple_model = Model(inputs = X_input, outputs = X, name='Simple_Model')\n",
    "    \n",
    "    \n",
    "    return simple_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = Simple_Model((standard_height, standard_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        (None, 280, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 286, 206, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 280, 200, 32)      4736      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 280, 200, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 280, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pool (MaxPooling2D)      (None, 140, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 448000)            0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 1)                 448001    \n",
      "=================================================================\n",
      "Total params: 452,865\n",
      "Trainable params: 452,801\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.compile(optimizer = \"Adam\",\n",
    "                     loss = \"binary_crossentropy\",\n",
    "                     metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 594 samples, validate on 72 samples\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 8s 13ms/step - loss: 7.8937 - acc: 0.4966 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 4s 7ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 4s 7ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 4s 7ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 4s 7ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history_simple = simple_model.fit(X_train,\n",
    "                                  Y_train,\n",
    "                                  epochs=5,\n",
    "                                  batch_size=16,\n",
    "                                  validation_data=(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尝试只用全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "def dense_model(input_shape):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "#     m, n_H, n_W, n_C = X_input.get_shape().as_list()\n",
    "    \n",
    "#     X = layers.core.Reshape([n_H*n_W, n_C])(X_input)\n",
    "    \n",
    "#     X = layers.core.Lambda(compute_layer_style)(X)\n",
    "    \n",
    "    X = layers.Flatten()(X_input)\n",
    "    \n",
    "    X = layers.Dense(512, activation='relu')(X)\n",
    "    \n",
    "    X = layers.Dense(512, activation='relu')(X)\n",
    "    \n",
    "    X = layers.Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    dense_model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    return dense_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model = dense_model((standard_height, standard_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 280, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 168000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               86016512  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 86,279,681\n",
      "Trainable params: 86,279,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model.compile(optimizer = \"Adam\",\n",
    "                    loss = \"binary_crossentropy\",\n",
    "                    metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 594 samples, validate on 72 samples\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 16s 26ms/step - loss: 7.7485 - acc: 0.5034 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 5s 9ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 6s 9ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 6s 9ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 6s 9ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "dense_simple = dense_model.fit(X_train,\n",
    "                               Y_train,\n",
    "                               epochs=5,\n",
    "                               batch_size=16,\n",
    "                               validation_data=(X_validation, Y_validation))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
